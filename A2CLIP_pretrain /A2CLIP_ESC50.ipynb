{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295d9ad2-cdd8-42f2-a54b-39f43255a1a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T16:56:42.805145Z",
     "iopub.status.busy": "2024-01-04T16:56:42.804590Z",
     "iopub.status.idle": "2024-01-04T16:56:44.751020Z",
     "shell.execute_reply": "2024-01-04T16:56:44.749644Z",
     "shell.execute_reply.started": "2024-01-04T16:56:42.805080Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import clip\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "from pathlib import Path\n",
    "import torch.optim as optim\n",
    "import torchaudio.transforms as T\n",
    "import torchvision.transforms as VT\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad1afbf-9a4e-4cbe-a112-28e50ec68627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T16:56:44.753187Z",
     "iopub.status.busy": "2024-01-04T16:56:44.752907Z",
     "iopub.status.idle": "2024-01-04T16:56:44.760314Z",
     "shell.execute_reply": "2024-01-04T16:56:44.759396Z",
     "shell.execute_reply.started": "2024-01-04T16:56:44.753165Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ESC50Dataset(Dataset):\n",
    "    def __init__(self, base_path, meta_path, fold):\n",
    "        self.base_path = base_path\n",
    "        self.df = pd.read_csv(meta_path)\n",
    "        self.df = self.df[self.df['fold'].isin(fold)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        filename = os.path.join(self.base_path, row['filename'])\n",
    "        label = row['category']\n",
    "        waveform, sample_rate = torchaudio.load(filename)\n",
    "        \n",
    "        spectrogram = T.MelSpectrogram(sample_rate=sample_rate)(waveform)\n",
    "\n",
    "        if spectrogram.shape[0] > 1:\n",
    "            spectrogram = spectrogram[0, :, :].unsqueeze(0)\n",
    "\n",
    "        mean = [0.485]\n",
    "        std = [0.229]\n",
    "        spectrogram = VT.Normalize(mean=mean, std=std)(spectrogram)\n",
    "\n",
    "        return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a645fcb9-4ac1-4bbd-8d93-d7cf14ee198a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T16:56:44.761035Z",
     "iopub.status.busy": "2024-01-04T16:56:44.760847Z",
     "iopub.status.idle": "2024-01-04T16:56:44.772268Z",
     "shell.execute_reply": "2024-01-04T16:56:44.771359Z",
     "shell.execute_reply.started": "2024-01-04T16:56:44.761015Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_path = 'ESC-50-master/audio'\n",
    "meta_path = 'ESC-50-master/meta/esc50.csv'\n",
    "fold = [1,2,3,4]\n",
    "\n",
    "dataset = ESC50Dataset(base_path, meta_path, fold)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acffb810-7293-4a7d-80be-f82cf459fa24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T16:56:44.772978Z",
     "iopub.status.busy": "2024-01-04T16:56:44.772793Z",
     "iopub.status.idle": "2024-01-04T16:56:44.780206Z",
     "shell.execute_reply": "2024-01-04T16:56:44.779293Z",
     "shell.execute_reply.started": "2024-01-04T16:56:44.772959Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AudioTextLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AudioTextLoss, self).__init__()\n",
    "        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
    "        self.loss_audio = nn.CrossEntropyLoss()\n",
    "        self.loss_text = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, audio_features, text_features):\n",
    "        # Normalize features\n",
    "        audio_features = audio_features / audio_features.norm(dim=-1, keepdim=True)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # Calculate cosine similarity as logits\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "        logits_per_audio = logit_scale * audio_features @ text_features.t()\n",
    "        logits_per_text = logit_scale * text_features @ audio_features.t()\n",
    "\n",
    "        # Calculate batch size for ground truth\n",
    "        batch_size = audio_features.shape[0]\n",
    "        ground_truth = torch.arange(batch_size, dtype=torch.long, device=audio_features.device)\n",
    "\n",
    "        # Compute loss as the average of audio-to-text and text-to-audio losses\n",
    "        return (\n",
    "            self.loss_audio(logits_per_audio, ground_truth)\n",
    "            + self.loss_text(logits_per_text, ground_truth)\n",
    "        ) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5b98b46-920c-45a0-bd0c-9472b034facf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T16:56:44.780897Z",
     "iopub.status.busy": "2024-01-04T16:56:44.780717Z",
     "iopub.status.idle": "2024-01-04T16:56:45.031169Z",
     "shell.execute_reply": "2024-01-04T16:56:45.029424Z",
     "shell.execute_reply.started": "2024-01-04T16:56:44.780878Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class MLPLayers(nn.Module):\n",
    "    def __init__(self, input_features, output_features, dropout_p=0.1):\n",
    "        super(MLPLayers, self).__init__()\n",
    "        self.nonlin = nn.ReLU()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(input_features, output_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(output_features, output_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(self.nonlin(x))\n",
    "\n",
    "resnet = models.resnet18(pretrained=False)\n",
    "\n",
    "resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = MLPLayers(input_features=num_ftrs, output_features=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e9b68e8-b5d1-4e0d-a45f-32047a2e2edf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T16:56:45.032519Z",
     "iopub.status.busy": "2024-01-04T16:56:45.032317Z",
     "iopub.status.idle": "2024-01-04T16:56:48.015208Z",
     "shell.execute_reply": "2024-01-04T16:56:48.014398Z",
     "shell.execute_reply.started": "2024-01-04T16:56:45.032497Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "clip_model = clip_model.eval()\n",
    "loss_fn=AudioTextLoss()\n",
    "resnet.to(device)\n",
    "clip_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a56f927-a588-4070-ae89-ce44a1eb537f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T16:56:48.016768Z",
     "iopub.status.busy": "2024-01-04T16:56:48.016607Z",
     "iopub.status.idle": "2024-01-04T17:07:46.576654Z",
     "shell.execute_reply": "2024-01-04T17:07:46.576009Z",
     "shell.execute_reply.started": "2024-01-04T16:56:48.016752Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.16678299009799957\n",
      "Epoch: 2, loss: 0.1575911045074463\n",
      "Epoch: 3, loss: 0.1485597789287567\n",
      "Epoch: 4, loss: 0.14164896309375763\n",
      "Epoch: 5, loss: 0.13647662103176117\n",
      "Epoch: 6, loss: 0.13156019151210785\n",
      "Epoch: 7, loss: 0.12815412878990173\n",
      "Epoch: 8, loss: 0.11982974410057068\n",
      "Epoch: 9, loss: 0.11282099783420563\n",
      "Epoch: 10, loss: 0.10784037411212921\n",
      "Epoch: 11, loss: 0.10320109128952026\n",
      "Epoch: 12, loss: 0.09850771725177765\n",
      "Epoch: 13, loss: 0.09768055379390717\n",
      "Epoch: 14, loss: 0.09242719411849976\n",
      "Epoch: 15, loss: 0.08992860466241837\n",
      "Epoch: 16, loss: 0.0870678499341011\n",
      "Epoch: 17, loss: 0.08135592937469482\n",
      "Epoch: 18, loss: 0.07952971011400223\n",
      "Epoch: 19, loss: 0.07517270743846893\n",
      "Epoch: 20, loss: 0.07180191576480865\n",
      "Epoch: 21, loss: 0.06798122078180313\n",
      "Epoch: 22, loss: 0.06451481580734253\n",
      "Epoch: 23, loss: 0.06459861248731613\n",
      "Epoch: 24, loss: 0.06161371245980263\n",
      "Epoch: 25, loss: 0.057276248931884766\n",
      "Epoch: 26, loss: 0.056595366448163986\n",
      "Epoch: 27, loss: 0.054111819714307785\n",
      "Epoch: 28, loss: 0.04874374717473984\n",
      "Epoch: 29, loss: 0.04880942404270172\n",
      "Epoch: 30, loss: 0.0474434494972229\n",
      "Epoch: 31, loss: 0.04588482901453972\n",
      "Epoch: 32, loss: 0.04586827754974365\n",
      "Epoch: 33, loss: 0.044010113924741745\n",
      "Epoch: 34, loss: 0.042241666465997696\n",
      "Epoch: 35, loss: 0.04010656848549843\n",
      "Epoch: 36, loss: 0.03922387585043907\n",
      "Epoch: 37, loss: 0.037899188697338104\n",
      "Epoch: 38, loss: 0.04212987422943115\n",
      "Epoch: 39, loss: 0.03948595002293587\n",
      "Epoch: 40, loss: 0.03801913186907768\n",
      "Epoch: 41, loss: 0.036380596458911896\n",
      "Epoch: 42, loss: 0.03513931855559349\n",
      "Epoch: 43, loss: 0.03503671661019325\n",
      "Epoch: 44, loss: 0.034332819283008575\n",
      "Epoch: 45, loss: 0.03169240429997444\n",
      "Epoch: 46, loss: 0.03089057095348835\n",
      "Epoch: 47, loss: 0.03350631520152092\n",
      "Epoch: 48, loss: 0.030915390700101852\n",
      "Epoch: 49, loss: 0.030198557302355766\n",
      "Epoch: 50, loss: 0.03207545727491379\n",
      "Epoch: 51, loss: 0.02933632954955101\n",
      "Epoch: 52, loss: 0.030467050150036812\n",
      "Epoch: 53, loss: 0.029509631916880608\n",
      "Epoch: 54, loss: 0.027395471930503845\n",
      "Epoch: 55, loss: 0.029275259003043175\n",
      "Epoch: 56, loss: 0.029695754870772362\n",
      "Epoch: 57, loss: 0.031571198254823685\n",
      "Epoch: 58, loss: 0.03020215593278408\n",
      "Epoch: 59, loss: 0.03506222739815712\n",
      "Epoch: 60, loss: 0.030713213607668877\n",
      "Epoch: 61, loss: 0.028162313625216484\n",
      "Epoch: 62, loss: 0.026264257729053497\n",
      "Epoch: 63, loss: 0.0373205691576004\n",
      "Epoch: 64, loss: 0.031980857253074646\n",
      "Epoch: 65, loss: 0.027973493561148643\n",
      "Epoch: 66, loss: 0.027038346976041794\n",
      "Epoch: 67, loss: 0.025775885209441185\n",
      "Epoch: 68, loss: 0.029057860374450684\n",
      "Epoch: 69, loss: 0.03285769000649452\n",
      "Epoch: 70, loss: 0.031246235594153404\n",
      "Epoch: 71, loss: 0.026362786069512367\n",
      "Epoch: 72, loss: 0.026250993832945824\n",
      "Epoch: 73, loss: 0.02944594994187355\n",
      "Epoch: 74, loss: 0.04139811545610428\n",
      "Epoch: 75, loss: 0.026965850964188576\n",
      "Epoch: 76, loss: 0.02489306963980198\n",
      "Epoch: 77, loss: 0.024565747007727623\n",
      "Epoch: 78, loss: 0.026994504034519196\n",
      "Epoch: 79, loss: 0.025329865515232086\n",
      "Epoch: 80, loss: 0.025841569527983665\n",
      "Epoch: 81, loss: 0.025776300579309464\n",
      "Epoch: 82, loss: 0.041979484260082245\n",
      "Epoch: 83, loss: 0.026552852243185043\n",
      "Epoch: 84, loss: 0.02698672004044056\n",
      "Epoch: 85, loss: 0.02417328581213951\n",
      "Epoch: 86, loss: 0.022738298401236534\n",
      "Epoch: 87, loss: 0.023676859214901924\n",
      "Epoch: 88, loss: 0.023899871855974197\n",
      "Epoch: 89, loss: 0.024900242686271667\n",
      "Epoch: 90, loss: 0.024363107979297638\n",
      "Epoch: 91, loss: 0.024389896541833878\n",
      "Epoch: 92, loss: 0.023312732577323914\n",
      "Epoch: 93, loss: 0.032451990991830826\n",
      "Epoch: 94, loss: 0.02892914228141308\n",
      "Epoch: 95, loss: 0.023769943043589592\n",
      "Epoch: 96, loss: 0.02554936893284321\n",
      "Epoch: 97, loss: 0.024387815967202187\n",
      "Epoch: 98, loss: 0.028598949313163757\n",
      "Epoch: 99, loss: 0.024287816137075424\n",
      "Epoch: 100, loss: 0.023110326379537582\n"
     ]
    }
   ],
   "source": [
    "def train(model, data_loader, optimizer, clip_model, epochs=30):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        loss_epoch=0\n",
    "        for spectrograms, labels in data_loader:\n",
    "            spectrograms = spectrograms.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            audio_features = model(spectrograms)\n",
    "            labels=[\"This is a sound of \"+label for label in labels]\n",
    "            text_tokens = clip.tokenize(labels).to(device)\n",
    "            with torch.no_grad():\n",
    "                text_features = clip_model.encode_text(text_tokens)\n",
    "            text_features = text_features.to(dtype=torch.float)\n",
    "            loss = loss_fn(audio_features, text_features)\n",
    "            loss_epoch += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # scheduler.step()\n",
    "        print(f\"Epoch: {epoch+1}, loss: {loss_epoch/len(dataset)}\")\n",
    "\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.1)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "train(resnet, dataloader, optimizer, clip_model, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d517a3b-3efb-4e5d-b7a3-9a837550748e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T17:07:46.577708Z",
     "iopub.status.busy": "2024-01-04T17:07:46.577539Z",
     "iopub.status.idle": "2024-01-04T17:07:46.711195Z",
     "shell.execute_reply": "2024-01-04T17:07:46.710322Z",
     "shell.execute_reply.started": "2024-01-04T17:07:46.577691Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_save_path = \"newresnet\"\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "torch.save(resnet, os.path.join(model_save_path, \"resnet_model.pth\"), pickle_module=dill)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
