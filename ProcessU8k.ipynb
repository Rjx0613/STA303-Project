{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09436d1d-79ec-451e-8538-380227e9fe0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T11:07:20.730780Z",
     "iopub.status.busy": "2024-01-06T11:07:20.729544Z",
     "iopub.status.idle": "2024-01-06T11:07:21.330460Z",
     "shell.execute_reply": "2024-01-06T11:07:21.329374Z",
     "shell.execute_reply.started": "2024-01-06T11:07:20.730699Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math, random\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import dill\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import clip\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "from pathlib import Path\n",
    "import torch.optim as optim\n",
    "import torchaudio.transforms as T\n",
    "import torchvision.transforms as VT\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e523e77-094f-4c1b-993c-ae0d6f0f13ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T11:07:24.310463Z",
     "iopub.status.busy": "2024-01-06T11:07:24.309986Z",
     "iopub.status.idle": "2024-01-06T11:07:24.348887Z",
     "shell.execute_reply": "2024-01-06T11:07:24.346409Z",
     "shell.execute_reply.started": "2024-01-06T11:07:24.310426Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AudioUtil:\n",
    "    @staticmethod\n",
    "    def open(audio_file):\n",
    "        sig, sr = torchaudio.load(audio_file)\n",
    "        return (sig, sr)\n",
    "\n",
    "    @staticmethod\n",
    "    def rechannel(aud, new_channel):\n",
    "        sig, sr = aud\n",
    "        if sig.shape[0] == new_channel:\n",
    "            return aud\n",
    "        if new_channel == 1:\n",
    "            resig = sig[:1, :]\n",
    "        else:\n",
    "            resig = torch.cat([sig, sig])\n",
    "        return (resig, sr)\n",
    "\n",
    "    @staticmethod\n",
    "    def resample(aud, newsr):\n",
    "        sig, sr = aud\n",
    "        if sr == newsr:\n",
    "            return aud\n",
    "        resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
    "        if sig.shape[0] > 1:\n",
    "            retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
    "            resig = torch.cat([resig, retwo])\n",
    "        return (resig, newsr)\n",
    "\n",
    "    @staticmethod\n",
    "    def pad_trunc(aud, max_ms, rand=False):\n",
    "        sig, sr = aud\n",
    "        max_len = sr // 1000 * max_ms\n",
    "        if sig.shape[1] > max_len:\n",
    "            sig = sig[:, :max_len]\n",
    "        elif sig.shape[1] < max_len:\n",
    "            pad_begin_len = random.randint(0, max_len - sig.shape[1]) if rand else 0\n",
    "            pad_end_len = max_len - sig.shape[1] - pad_begin_len\n",
    "            pad_begin = torch.zeros((sig.shape[0], pad_begin_len))\n",
    "            pad_end = torch.zeros((sig.shape[0], pad_end_len))\n",
    "            sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
    "        return (sig, sr)\n",
    "\n",
    "    @staticmethod\n",
    "    def time_shift(aud, shift_limit):\n",
    "        sig, sr = aud\n",
    "        shift_amt = int(random.random() * shift_limit * sig.shape[1])\n",
    "        return (sig.roll(shift_amt), sr)\n",
    "\n",
    "    @staticmethod\n",
    "    def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
    "        sig, sr = aud\n",
    "        spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "        spec = transforms.AmplitudeToDB(top_db=80)(spec)\n",
    "        return spec\n",
    "\n",
    "    @staticmethod\n",
    "    def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
    "        aug_spec = spec\n",
    "        freq_mask_param = max_mask_pct * spec.shape[1]\n",
    "        for _ in range(n_freq_masks):\n",
    "            aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec)\n",
    "        time_mask_param = max_mask_pct * spec.shape[2]\n",
    "        for _ in range(n_time_masks):\n",
    "            aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec)\n",
    "        return aug_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40bd4f87-c989-4199-9e64-59d32f683c06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T11:07:27.154169Z",
     "iopub.status.busy": "2024-01-06T11:07:27.152115Z",
     "iopub.status.idle": "2024-01-06T11:07:27.179052Z",
     "shell.execute_reply": "2024-01-06T11:07:27.176605Z",
     "shell.execute_reply.started": "2024-01-06T11:07:27.154046Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SoundDS(Dataset):\n",
    "    def __init__(self, df, data_path, apply_augmentation=True):\n",
    "        self.df = df\n",
    "        self.data_path = str(data_path)\n",
    "        self.duration = 4000\n",
    "        self.sr = 44100\n",
    "        self.channel = 2\n",
    "        self.apply_augmentation = apply_augmentation  # 控制是否应用数据增强\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_file = self.data_path + self.df.loc[idx, 'path']\n",
    "        class_id = self.df.loc[idx, 'label']\n",
    "\n",
    "        aud = AudioUtil.open(audio_file)\n",
    "        reaud = AudioUtil.resample(aud, self.sr)\n",
    "        rechan = AudioUtil.rechannel(reaud, self.channel)\n",
    "\n",
    "        # 应用或跳过时间偏移\n",
    "        if self.apply_augmentation:\n",
    "            dur_aud = AudioUtil.pad_trunc(rechan, self.duration,True)\n",
    "            shift_aud = AudioUtil.time_shift(dur_aud, 0.2)\n",
    "        else:\n",
    "            dur_aud = AudioUtil.pad_trunc(rechan, self.duration)\n",
    "            shift_aud = dur_aud\n",
    "\n",
    "        sgram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "\n",
    "        # 应用或跳过频谱图增强\n",
    "        if self.apply_augmentation:\n",
    "            aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1,n_freq_masks=2, n_time_masks=2)\n",
    "        else:\n",
    "            aug_sgram = sgram\n",
    "\n",
    "        return aug_sgram, class_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa85f69d-1e54-442a-a186-b57f0eb259e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T11:07:29.005288Z",
     "iopub.status.busy": "2024-01-06T11:07:29.004609Z",
     "iopub.status.idle": "2024-01-06T11:07:29.239564Z",
     "shell.execute_reply": "2024-01-06T11:07:29.237845Z",
     "shell.execute_reply.started": "2024-01-06T11:07:29.005219Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"train_test/Utrain.csv\")\n",
    "df_test=pd.read_csv(\"train_test/Utest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "347bd967-1d48-4eb5-84f2-21acbb6a1f95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T11:07:30.433864Z",
     "iopub.status.busy": "2024-01-06T11:07:30.433196Z",
     "iopub.status.idle": "2024-01-06T11:07:30.445729Z",
     "shell.execute_reply": "2024-01-06T11:07:30.443613Z",
     "shell.execute_reply.started": "2024-01-06T11:07:30.433797Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train=SoundDS(df_train,\"UrbanSound8K/audio/\",True)\n",
    "dataset_test=SoundDS(df_test,\"UrbanSound8K/audio/\",False)\n",
    "dataloader_train=DataLoader(dataset_train,batch_size=128,shuffle=True)\n",
    "dataloader_test=DataLoader(dataset_test,batch_size=128,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da916be0-03dc-4e9d-ae43-6db5bfa07c04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T11:07:33.762627Z",
     "iopub.status.busy": "2024-01-06T11:07:33.761954Z",
     "iopub.status.idle": "2024-01-06T11:07:33.780999Z",
     "shell.execute_reply": "2024-01-06T11:07:33.778825Z",
     "shell.execute_reply.started": "2024-01-06T11:07:33.762558Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AudioTextLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AudioTextLoss, self).__init__()\n",
    "        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
    "        self.loss_audio = nn.CrossEntropyLoss()\n",
    "        self.loss_text = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, audio_features, text_features):\n",
    "        # Normalize features\n",
    "        audio_features = audio_features / audio_features.norm(dim=-1, keepdim=True)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        # Calculate cosine similarity as logits\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "        logits_per_audio = logit_scale * audio_features @ text_features.t()\n",
    "        logits_per_text = logit_scale * text_features @ audio_features.t()\n",
    "\n",
    "        # Calculate batch size for ground truth\n",
    "        batch_size = audio_features.shape[0]\n",
    "        ground_truth = torch.arange(batch_size, dtype=torch.long, device=audio_features.device)\n",
    "\n",
    "        # Compute loss as the average of audio-to-text and text-to-audio losses\n",
    "        return (\n",
    "            self.loss_audio(logits_per_audio, ground_truth)\n",
    "            + self.loss_text(logits_per_text, ground_truth)\n",
    "        ) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb6f1284-a172-4262-be27-86895b0405f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T11:07:35.656599Z",
     "iopub.status.busy": "2024-01-06T11:07:35.655878Z",
     "iopub.status.idle": "2024-01-06T11:07:36.210659Z",
     "shell.execute_reply": "2024-01-06T11:07:36.208418Z",
     "shell.execute_reply.started": "2024-01-06T11:07:35.656528Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPLayers(nn.Module):\n",
    "    def __init__(self, input_features, output_features, dropout_p=0.1):\n",
    "        super(MLPLayers, self).__init__()\n",
    "        self.nonlin = nn.ReLU()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(input_features, output_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(output_features, output_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(self.nonlin(x))\n",
    "\n",
    "resnet =models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "resnet.conv1 = nn.Conv2d(2, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = MLPLayers(input_features=num_ftrs, output_features=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df54b4e2-f3eb-4a72-b10d-8dd51789f4b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T11:07:37.538055Z",
     "iopub.status.busy": "2024-01-06T11:07:37.537427Z",
     "iopub.status.idle": "2024-01-06T11:07:52.938388Z",
     "shell.execute_reply": "2024-01-06T11:07:52.937360Z",
     "shell.execute_reply.started": "2024-01-06T11:07:37.537992Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 338M/338M [00:11<00:00, 32.0MiB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n",
    "clip_model = clip_model.eval()\n",
    "loss_fn=AudioTextLoss()\n",
    "resnet.to(device)\n",
    "clip_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7b08a49-83d8-4686-a7bd-73795a001426",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T11:07:53.045148Z",
     "iopub.status.busy": "2024-01-06T11:07:53.044722Z",
     "iopub.status.idle": "2024-01-06T11:07:53.053078Z",
     "shell.execute_reply": "2024-01-06T11:07:53.051778Z",
     "shell.execute_reply.started": "2024-01-06T11:07:53.045122Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, clip_model, epochs=30):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        loss_epoch=0\n",
    "        for spectrograms,labels in tqdm(data_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            # print(labels)\n",
    "            spectrograms = spectrograms.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            audio_features = model(spectrograms)\n",
    "            labels=[\"This is a sound of \"+label for label in labels]\n",
    "            text_tokens = clip.tokenize(labels).to(device)\n",
    "            with torch.no_grad():\n",
    "                text_features = clip_model.encode_text(text_tokens)\n",
    "            text_features = text_features.to(dtype=torch.float)\n",
    "            loss = loss_fn(audio_features, text_features)\n",
    "            loss_epoch += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step(loss_epoch/len(dataset_train))\n",
    "        print(f\"Epoch: {epoch+1}, loss: {loss_epoch/len(dataset_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3023893a-93cb-48eb-b88d-9bd263c7c062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T11:08:03.799872Z",
     "iopub.status.busy": "2024-01-06T11:08:03.799384Z",
     "iopub.status.idle": "2024-01-06T11:08:03.809484Z",
     "shell.execute_reply": "2024-01-06T11:08:03.807091Z",
     "shell.execute_reply.started": "2024-01-06T11:08:03.799826Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(resnet.parameters(), lr=0.1)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=5, eta_min=0.01)\n",
    "\n",
    "train(resnet, dataloader_train, optimizer, clip_model, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1197546f-25c2-41ad-b251-5bc22761304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"UrbanSoundResnet\"\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "torch.save(resnet, os.path.join(model_save_path, \"resnet_model.pth\"), pickle_module=dill)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8420742-4d2f-403f-9ee5-ff3538a02e80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model next train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f44f9d4c-159e-4122-a3a9-c6a75e9da6cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T11:08:21.749176Z",
     "iopub.status.busy": "2024-01-06T11:08:21.748504Z",
     "iopub.status.idle": "2024-01-06T11:08:22.030177Z",
     "shell.execute_reply": "2024-01-06T11:08:22.028619Z",
     "shell.execute_reply.started": "2024-01-06T11:08:21.749109Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(2, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): MLPLayers(\n",
       "    (nonlin): ReLU()\n",
       "    (sequential): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_test = torch.load('UrbanSoundResnet/resnet_model.pth', pickle_module=dill)\n",
    "resnet_test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91305319-f6e8-43e0-b0e4-e208cb8a7a34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T11:08:25.053824Z",
     "iopub.status.busy": "2024-01-06T11:08:25.053122Z",
     "iopub.status.idle": "2024-01-06T11:35:19.117021Z",
     "shell.execute_reply": "2024-01-06T11:35:19.116468Z",
     "shell.execute_reply.started": "2024-01-06T11:08:25.053753Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 62/62 [01:55<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.02336684614419937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 62/62 [00:53<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 0.022436875849962234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 62/62 [00:51<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, loss: 0.02223445102572441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 62/62 [00:51<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 0.022237107157707214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 62/62 [00:51<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, loss: 0.02207835018634796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, loss: 0.021945444867014885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 62/62 [00:50<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, loss: 0.02189304493367672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 62/62 [00:50<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, loss: 0.02192847989499569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, loss: 0.021883022040128708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 0.02177342213690281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 62/62 [00:51<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, loss: 0.02174779772758484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, loss: 0.021778089925646782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 62/62 [00:51<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, loss: 0.02169603295624256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 62/62 [00:52<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, loss: 0.021706121042370796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, loss: 0.021588385105133057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 62/62 [00:51<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, loss: 0.02159712091088295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 62/62 [00:52<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, loss: 0.021624134853482246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 62/62 [00:52<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, loss: 0.021613264456391335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 62/62 [00:51<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, loss: 0.02158198691904545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 62/62 [00:51<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, loss: 0.0215392354875803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 62/62 [00:51<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, loss: 0.021601952612400055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 62/62 [00:51<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, loss: 0.02155141346156597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 62/62 [00:51<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, loss: 0.021569067612290382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 62/62 [00:52<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, loss: 0.02154034934937954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 62/62 [00:51<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, loss: 0.02149629406630993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 62/62 [00:51<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, loss: 0.021556053310632706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 62/62 [00:51<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, loss: 0.021466746926307678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, loss: 0.02150634489953518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 62/62 [00:51<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, loss: 0.021446295082569122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 62/62 [00:50<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, loss: 0.02146325819194317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "optimizer = optim.AdamW(resnet_test.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "train(resnet_test, dataloader_train, optimizer, clip_model, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a2e8049-2c9c-4e01-b12d-415a2d24e3d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T11:35:19.118793Z",
     "iopub.status.busy": "2024-01-06T11:35:19.118609Z",
     "iopub.status.idle": "2024-01-06T11:35:19.197576Z",
     "shell.execute_reply": "2024-01-06T11:35:19.197094Z",
     "shell.execute_reply.started": "2024-01-06T11:35:19.118774Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_save_path = \"UrbanSoundResnet\"\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "torch.save(resnet, os.path.join(model_save_path, \"resnet_model_60epoch.pth\"), pickle_module=dill)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a4ac6-354b-4e28-83c0-f3f193073f05",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3299e50c-4e35-486d-8e70-70f6aefe1597",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T11:38:32.192194Z",
     "iopub.status.busy": "2024-01-06T11:38:32.191905Z",
     "iopub.status.idle": "2024-01-06T11:38:32.202359Z",
     "shell.execute_reply": "2024-01-06T11:38:32.200681Z",
     "shell.execute_reply.started": "2024-01-06T11:38:32.192167Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['car_horn', 'dog_bark', 'air_conditioner', 'children_playing',\n",
       "       'siren', 'engine_idling', 'jackhammer', 'drilling', 'street_music',\n",
       "       'gun_shot'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes=dataset_test.df['label'].unique()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22e4afed-251f-412f-b27a-d707bcae7dbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T11:38:36.526864Z",
     "iopub.status.busy": "2024-01-06T11:38:36.526152Z",
     "iopub.status.idle": "2024-01-06T11:38:36.674878Z",
     "shell.execute_reply": "2024-01-06T11:38:36.674287Z",
     "shell.execute_reply.started": "2024-01-06T11:38:36.526791Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_classes=[]\n",
    "for c in classes:\n",
    "    # print(c)\n",
    "    c = \"This is a sound of \" + c\n",
    "    text_tokens=clip.tokenize(c).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features=clip_model.encode_text(text_tokens)\n",
    "    text_features=text_features.to(dtype=torch.float)\n",
    "    feature_classes.append(text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92850fa5-743e-4b62-b981-87ea2c9742b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-05T17:25:32.975131Z",
     "iopub.status.busy": "2024-01-05T17:25:32.974881Z",
     "iopub.status.idle": "2024-01-05T17:25:33.022636Z",
     "shell.execute_reply": "2024-01-05T17:25:33.021804Z",
     "shell.execute_reply.started": "2024-01-05T17:25:32.975108Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(2, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): MLPLayers(\n",
       "    (nonlin): ReLU()\n",
       "    (sequential): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_test = torch.load('UrbanSoundResnet/resnet_model.pth', pickle_module=dill)\n",
    "resnet_test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e89321b2-abe5-4d2e-b31b-5218393f0c59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-06T11:44:16.726593Z",
     "iopub.status.busy": "2024-01-06T11:44:16.726323Z",
     "iopub.status.idle": "2024-01-06T11:44:22.960687Z",
     "shell.execute_reply": "2024-01-06T11:44:22.959933Z",
     "shell.execute_reply.started": "2024-01-06T11:44:16.726568Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "817\n",
      "855\n",
      "Acc: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "acc=0\n",
    "for spectrograms, labels in dataloader_test:\n",
    "    spectrograms = spectrograms.to(device)\n",
    "    print()\n",
    "    audio_features = resnet_test(spectrograms)\n",
    "    logit = torch.stack([torch.stack([F.cosine_similarity(audio.unsqueeze(0), text) for text in feature_classes]) for audio in audio_features])\n",
    "    _,topk_index=torch.topk(logit,k=1,dim=1)\n",
    "    indices = [np.where(classes == label)[0][0] for label in labels]\n",
    "    topk_index_numpy = topk_index.cpu().numpy()\n",
    "    for i, index in enumerate(indices):\n",
    "        if index in topk_index_numpy[i]:\n",
    "            acc += 1\n",
    "print(acc)\n",
    "print(len(dataset_test))\n",
    "print(f\"Acc: {acc/len(dataset_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
